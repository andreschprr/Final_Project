#the project's intention is to scrape data from Indian election 2019 for each of the 542 constituencies, and regress margin of victory in each constituency on a few different independent variables. 
# there are three independent variables: 1. dummy variable political party of winning candidate; 2. total number of votes cast in the constituency; 3. total number of candidates in the constituency
# there are two sets of URLs from which data has been scraped (each of these URLs keeps changing slightly to depict the different states and the constituencies within them, though the general format remains the same): 1. http://results.eci.gov.in/pc/en/trends/statewiseU011.htm; 2. http://results.eci.gov.in/pc/en/constituencywise/ConstituencywiseS033.htm


import csv
import requests
from bs4 import BeautifulSoup
import pandas as pd

#declaring empty lists for each of the variables to be scraped
#the first variable to be scraped is number of candidates in each constituency
number_of_candidates = []

#the second variable to be scraped is total votes polled in each constituency
total_votes = []
# td_list is a list which is used to append total_votes
td_list = []

#the third variable to be scraped is total votes polled in each constituency
tentative1_name_of_const = []
tentative2_name_of_const = []
name_of_const = []



#declaring lists of code of state and page numbers to deal with changing URLs
# code_of_state deals with different states whereas page_number deals with constituencies within each state
# initially only a few states and pages have been declared to make the code run quickly
page_number = ['1','2','3']
code_of_state = ['01', '02']

# 'S' is for states whereas 'U' is for Union Territories
state_ut = ['S', 'U']


# define first scrape function here
for j in (code_of_state):
    for i in (page_number):
        for k in (state_ut): 
          # page iterates over the changing URLs
            page = requests.get('http://results.eci.gov.in/pc/en/constituencywise/Constituencywise' + k + j + i +'.htm')
            soup = BeautifulSoup(page.content, 'html.parser')
          
          # the next three lines of code scrape our first variable of interest - number of candidates in the given constituency
          # full_table scrapes the HTML code for each row except the last; each row is depicted by the tr tag "font-size:12px;"; the first column of each row contains the serial number of candidate 
          # full_table will take null values for all URLs that don't exist. for example, the URL with code_of_state = 02 and page_number = 3 does not exist
          
            full_table = soup.find_all(attrs={"style":"font-size:12px;"})
          # the if condition takes care of the null values of full_table
          # the length of full_table is appended to number_of_candidates because our variable of interest, total number of candidates in the given constituency, is equal to length of full_table
            if (len(full_table) is not 0):
                number_of_candidates.append(len(full_table))
            
            # the next bit of code scrapes our second variable of interest - total votes polled in the given constituency
            # last_row scrapes the HTML code for the last row (coloured in blue), which contains our second variable of interest
            # last_row will take null values for all URLs that don't exist. for example, the URL with code_of_state = 02 and page_number = 3 does not exist
            last_row = soup.find(attrs={"style":"color: #fff; background: #105980; border-color:#673033; border-width:1px;border-style:Solid;font-family:Calibri;"})
            # the if condition takes care of the null values of table  
            if (last_row is not None):
            # td_list contains each column in the last row
                td_list = last_row.find_all("td")
            # our variable of interest is in the sixth (index 5), so we append that to the list total_votes
                total_votes.append(td_list[5].get_text())
            
            # the next bit of code scrapes our third variable of interest - name of constituency
            name_row = soup.find(class_="table-party")
            if (name_row is not None):
                tentative1_name_of_const.append(name_row.find("tr").get_text())
                # the name has been split at "-" below because it is scraped as "Name of State-Name of constituency" while we only need the name of constituency 
                tentative2_name_of_const.append(tentative_name_of_const[-1].strip().split("-"))
                
# converting tentative2_name_of_const to a tuple to extract the name of constituency from tentative2_name_of_const                
x = tuple(tentative2_name_of_const)
name_of_const = [lis[1] for lis in x]    

# combining the lists for all variables together and converting into dataframe
combined_list = list(zip(name_of_const, number_of_candidates, total_votes))
df_const_candidates_votes = pd.DataFrame(np.array(combined_list), columns = list("abc"))
df_const_candidates_votes.columns = ['Constituency', 'Candidates', 'Votes']
            

# define second scrape function here
# scraping name of political party, margin of victory and name of constituency
#declaring empty lists for each of the variables to be scraped

#the first variable to be scraped is margin of victory in each constituency
margin_of_victory = []

#the second third variable to be scraped is the party to which the winning candidate belongs
party_name = []

#the third variable to be scraped is name of each constituency
name_of_const = []


for j in (code_of_state):
    for i in (page_number):
        for k in (state_ut): 
            # page iterates over the changing URLs
            page = requests.get('http://results.eci.gov.in/pc/en/trends/statewise' + k + j + i +'.htm')
            soup = BeautifulSoup(page.content, 'html.parser')
            full_table = soup.find_all(attrs={"style":"font-size:12px;"})
            for td in full_table:
                margin_of_victory.append(td.find(attrs={"align":"right"}).get_text())
                party_name.append(td.find("tbody").find("td").get_text())
                name_of_const.append(td.find('td').get_text())          

# combining the lists for all variables together and converting into dataframe
combined_list = list(zip(margin_of_victory, party_name, name_of_const))
df_const_margin_party = pd.DataFrame(np.array(combined), columns = list("abc"))
df_const_margin_party.columns = ['Constituency', 'Margin', 'Party']



# define merge function here
df_merged = pd.merge(df_const_candidates_votes, df_const_margin_party, on='Constituency')
     
  
  
# define regression function here
reg = linear_model.LinearRegression()
reg.fit(df_merged[['Candidates', 'Votes']], df_merged['Margin'])
print(reg.coef_)
